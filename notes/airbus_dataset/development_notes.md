# Day 1: 02-01-2025

We will be using the Airbus Ship Detection dataset which can be found in [Kaggle](https://www.kaggle.com/competitions/airbus-ship-detection). This dataset contains two different pieces of information:

* **Training information**: on the one hand, the dataset provides the user with data that can be used to train the models to be used in the original competition, including object detection models (e.g., YOLO), segmentation models (e.g.,  UNet), etc.

* **Submission information**: similarly, the dataset contains input images whose predictions, performed with any sort of technique, can be submitted to the competition, so as to obtain an evaluation of how good the model solves the task proposed in the original competition.

Since the dataset is used for academic purposes, completely allowed and supported by their creators as shown in the [license](https://www.kaggle.com/competitions/airbus-ship-detection), information related to the submission will not be used. Conversely, the training information will be used to obtain: (I) satellite imagery of seas and oceans without ships, which will be used as the "non-anomalous" samples of data; and (II) satellite imagery of seas and oceans including images with and without ships. This split of data allows us to train anomaly detection models, evaluating their goodness on known, ground truth, satellite imagery. For this reason, the original training dataset will be divided into three different partitions: train, validation and test. The first partition will be used for training the models, the second one will be used for deciding the best hyperparameters for the models, and the latter will be used for evaluating their goodness. This decision looks optimal because the datasets employed are big, thus there is enough information for training the models and evaluating them in an honest manner.

# Day 2: 03-01-2025

Another relevant aspect to be considered is the required preprocessing in the data. Regarding the Airbus Ship Detection dataset, several preprocessing steps are required to maximise the quality of the data to be used for training models:

* **Tile generation**: the input images of the dataset have a shape of 3x768x768. Since these images have a relatively big shape, each individual image is split into a grid of 9 different sub-images of size 3x256x256. The application of this tiling strategy is two-fold: (I) on the one hand, it allows us to obtain multiple tiles (anomalous and non-anomalous) for a single individual image, effectively increasing the size of the data to be used for training and developing more effective models; on the other hand (II), using smaller tiles contributes to a reduction of the memory usage, as the computational device employed has a limited amount of GPU VRAM (6GB).

* **Data normalisation**: firstly, applying normalisation to the input data can lead to more robust and effective models [Normalization effects on deep neural networks Jiahui Yu, Konstantinos Spiliopoulos], thus Mean-Scale (or Z-score) normalisation will be applied, as it can make the resulting model more robust to datasets with outliers or unfound values in the training dataset [omogeneous Data Normalization and Deep Learning: A Case Study in Human Activity Classification].

* **Mask calculation**: furthermore, the input dataset only provides information about the borders of each ship. While such information is useful, ship masks are required, so that tiles can be split into tiles without ships (non-anomalous) and tiles with ships (anomalous).

With all this in mind, the development started by using the AFML framework to create a basic pipeline that could apply these preprocessing steps automatically. The introduction of MLOps frameworks, such as Automation Framework for Machine Learning ([AFML](https://github.com/AlbertoVelascoMata/afml)), is the quality improvement of the resulting models, even in production environments [AI-powered DevOps and MLOps frameworks: Enhancing collaboration, automation, and scalability in machine learning pipelines].