{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional AutoEncoder: Visual Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides visual insights on the effect of the convolutional autoencoder trained to carry out anomaly detection on the MASATI (v2) dataset.\n",
    "\n",
    "Raúl Barba Rojas developed this notebook as part of his Master Thesis *Visual Anomaly Detection in Satellite Imagery* directed by Jorge Díez Peláez and co-directed by José Luis Espinosa Aranda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following python modules are required for the notebook to run smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from aerial_anomaly_detection.models.autoencoder import AutoEncoder\n",
    "from aerial_anomaly_detection.datasets import DataLoader\n",
    "from aerial_anomaly_detection.datasets.masati_v2 import MASATIv2\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the MASATI (v2) dataset using the code developed as part of the `aerial_anomaly_detection` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "val_dataset = MASATIv2.load(r'..\\..\\data\\processed\\MASATI-v2', 'val')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the trained AutoEncoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = AutoEncoder(1000, 32, 32).to(device)\n",
    "autoencoder.load_state_dict(torch.load(r'..\\..\\models\\AutoEncoder\\autoencoder_l1000_w32_h32_bs256_lr001.pth', weights_only = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, let us carry out the visual inspection of the autoencoder on validation data for simply one given batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 5\n",
    "(output_folder := Path('visual_output')).mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "autoencoder.eval()\n",
    "with torch.inference_mode():\n",
    "    for sample_name, X, _ in val_dataloader:\n",
    "        X = X.to(device)\n",
    "        y_pred = autoencoder(X).detach().cpu().numpy()\n",
    "        fig, axs = plt.subplots(ncols = batch_size, nrows = 2, figsize = (10, 7))\n",
    "\n",
    "        for idx_sample in range(batch_size):\n",
    "            sample_img = (((X[idx_sample,...].cpu().numpy() + 1) / 2) * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "            sample_pred = (((y_pred[idx_sample,...] + 1) / 2) * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "\n",
    "            axs[0, idx_sample].imshow(sample_img)\n",
    "            axs[0, idx_sample].axis(False)\n",
    "            axs[0, idx_sample].set_xticks([])\n",
    "            axs[0, idx_sample].set_yticks([])\n",
    "\n",
    "            axs[1, idx_sample].imshow(sample_pred)\n",
    "            axs[1, idx_sample].axis(False)\n",
    "            axs[1, idx_sample].set_xticks([])\n",
    "            axs[1, idx_sample].set_yticks([])\n",
    "\n",
    "        fig.text(s = 'Original', fontsize=16, x = 0.44, y=0.8)\n",
    "        fig.text(s = 'AutoEncoder', fontsize=16, x = 0.42, y=0.425)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_folder / f'batch_{num_batches}.png')\n",
    "        plt.close()\n",
    "        num_batches -= 1\n",
    "        if num_batches == 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
